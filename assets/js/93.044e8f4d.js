(window.webpackJsonp=window.webpackJsonp||[]).push([[93],{378:function(e,n,t){"use strict";t.r(n);var a=t(7),r=Object(a.a)({},(function(){var e=this,n=e._self._c;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("p",[e._v("只有当任务都是同类型的并且相互独立时，线程池的性能才能达到最佳。")]),e._v(" "),n("p",[e._v("如果某些任务依赖于其他的任务，那么会要求线程池足够大，从而确保它们依赖任务不会被放入等待队列中或者被拒绝，而采用线程封闭机制的任务需要串行执行。")]),e._v(" "),n("h2",{attrs:{id:"_1-在任务与执行策略之间的隐形耦合"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-在任务与执行策略之间的隐形耦合"}},[e._v("#")]),e._v(" 1. 在任务与执行策略之间的隐形耦合")]),e._v(" "),n("h3",{attrs:{id:"_1-1-线程饥饿死锁"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-线程饥饿死锁"}},[e._v("#")]),e._v(" 1.1 线程饥饿死锁")]),e._v(" "),n("p",[e._v("如果线程池中的任务需要无限期的等待一些必须由池中其他任务才能提供的资源或条件，例如某个任务等待另一个任务的返回值或执行结果，那么除非线程池足够大，否则将发生线程饥饿死锁。")]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v('****** 程序清单8-1 在单线程Executor中任务发生死锁 ******\n\npublic class ThreadDeadLock{\n    ExecutorService exec = Executors.newSingleThreadExecutor();\n    \n    public class RenderPageTask implements Callable<String>{\n        @Override\n        public String call() throws Exception {\n            Future<String> header,footer;\n            header = exec.submit(new LoadFileTask("header.html"));\n            footer = exec.submit(new LoadFileTask("footer.html"));\n            String page = renderBody();\n            // 将发生死锁-由于任务在等待子任务的结果\n            return header.get() + page + footer.get();\n        }\n    }\n}\n')])])]),n("h3",{attrs:{id:"_1-2-运行时间较长的任务"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-运行时间较长的任务"}},[e._v("#")]),e._v(" 1.2 运行时间较长的任务")]),e._v(" "),n("p",[e._v("有一项技术可以缓解执行时间较长任务造成的影响，即限定任务等待资源的时间，而不是无限制的等待。如果在线程之中总是充满了被阻塞的任务，那么也可能表明线程池的规模过小。")]),e._v(" "),n("h2",{attrs:{id:"_2-设置线程池的大小"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-设置线程池的大小"}},[e._v("#")]),e._v(" 2. 设置线程池的大小")]),e._v(" "),n("p",[e._v("对于计算密集型的任务，在拥有N个处理器的系统上，当线程池的大小为N+1时通常能实现最优的利用率。")]),e._v(" "),n("p",[e._v("对于包括I/O操作或者其他阻塞的操作任务，由于线程并不会一直执行，因此线程池的规模应该更大。")]),e._v(" "),n("p",[e._v("还有一个线程池大小的参考公式\n$$\nN(线程池大小) = N(cpu数量) * U(cpu利用率) * ( 1 + W(任务等待时间)/C(任务计算完成时间) )\n$$")]),e._v(" "),n("h2",{attrs:{id:"_3-配置threadpoolexecutor"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-配置threadpoolexecutor"}},[e._v("#")]),e._v(" 3. 配置ThreadPoolExecutor")]),e._v(" "),n("p",[n("code",[e._v("ThreadPoolExecutor")]),e._v("是一个灵活的、稳定的线程池，允许进行各种定制。如果默认的执行策略不能满足需求，那么可以通过"),n("code",[e._v("ThreadPoolExecutor")]),e._v("的构造函数来实例化一个对象，并根据自己的需求来定制。")]),e._v(" "),n("h3",{attrs:{id:"_3-1-线程的创建与销毁"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-线程的创建与销毁"}},[e._v("#")]),e._v(" 3.1 线程的创建与销毁")]),e._v(" "),n("p",[e._v("线程池的基本大小也就是线程池的目标大小，即在没有任务执行时线程池的大小，并且只有在工作列满了的情况下才会创建超出这个数量的线程。")]),e._v(" "),n("p",[e._v("线程池的最大大小表示可同时活动的线程数量的上限，如果某个线程的空闲时间超过了存活时间，那么该线程被标记为可回收的，并且当线程是当前大小超过了基本大小时，这个线程将被终止。")]),e._v(" "),n("h3",{attrs:{id:"_3-2-管理队列任务"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-管理队列任务"}},[e._v("#")]),e._v(" 3.2 管理队列任务")]),e._v(" "),n("p",[n("code",[e._v("ThreadPoolExecutor")]),e._v("允许提供一个"),n("code",[e._v("BlockingQueue")]),e._v("来保存等待执行的任务。")]),e._v(" "),n("p",[e._v("基本的任务排队方法有3种：无界队列、有界队列和同步移交。")]),e._v(" "),n("p",[n("code",[e._v("newFixedThreadPool")]),e._v("和"),n("code",[e._v("newSingleThreadExector")]),e._v("在默认情况下使用一个无界的"),n("code",[e._v("LinkedBlockingQueue")]),e._v("。如果所有工作者线程都处于忙碌状态，那么任务将在队列中等候，如果任务持续快速的到达，并且超过了线程池处理它们的速度，那么队列将无限制的增加。")]),e._v(" "),n("p",[e._v("在使用有界的工作队列时，队列的大小与线程池的大小必须一起调节，如果线程池较小而队列较大，那么有助于减少内存使用量，降低CPU的使用率，同时还可以减少上下文切换，但付出的代价是可能会限制吞吐量。")]),e._v(" "),n("p",[e._v("对于非常大的或者无界的线程池，可以通过使用"),n("code",[e._v("SynchronousQueue")]),e._v("来避免任务排队，以及直接将任务从生产者移交给工作者线程。"),n("code",[e._v("SynchronousQueue")]),e._v("不是一个真正的队列，而是一种在线程之间进行移交的机制，要将一个元素放入其中，必须有另一个线程正在等待接受这个元素，如果没有线程正在等待，并且线程的当前大小小于最大值，那么将创建一个新的线程，否则根据饱和策略，这个任务将被拒绝。使用直接移交将更高效，因为任务会直接移交给执行它的线程，而不是被首先放在队列中，然后由工作者线程从队列中提取该任务，只有当线程池是无限的或者可以拒绝任务时，"),n("code",[e._v("SynchronousQueue")]),e._v("才有实际价值，在"),n("code",[e._v("newCachedThreadPool")]),e._v("工厂方法中就是用了"),n("code",[e._v("SynchronousQueue")]),e._v("。")]),e._v(" "),n("p",[e._v("只有当任务相互独立时，为线程池或工作队列设置界限才是合理的，如果任务之间存在依赖性，那么有界的线程池或队列就可能导致线程饥饿死锁问题，此时应该使用无界的线程池。")]),e._v(" "),n("h3",{attrs:{id:"_3-3-饱和策略"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-饱和策略"}},[e._v("#")]),e._v(" 3.3 饱和策略")]),e._v(" "),n("ol",[n("li",[n("p",[e._v("“终止”策略")]),e._v(" "),n("p",[e._v("默认的饱和策略，该策略将抛出未检查的"),n("code",[e._v("RejectedExecutionException")]),e._v("，调用者可以捕获这个异常，然后根据需求编写自己的处理代码。当新提交的任务无法保存到队列中等待执行时，”抛弃”策略会悄悄抛弃该任务。")])]),e._v(" "),n("li",[n("p",[e._v("“抛弃最旧的”策略")]),e._v(" "),n("p",[e._v("会抛弃下一个将被执行的任务，然后尝试重新提交新的任务（如果工作队列是一个优先队列，那么”抛弃最旧的”策略将导致抛弃优先级最高的任务!!!）。")])]),e._v(" "),n("li",[n("p",[e._v("“调用者运行”策略")]),e._v(" "),n("p",[e._v("实现了一种机制，该策略既不会抛弃任务，也不会抛出异常，而是将某些任务回退到调用者，从而降低新任务的流量，它不会在线程池的某个线程中执行新提交的任务，而是在一个调用了execute的线程中执行的任务。")])])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("****** 程序清单8-4 使用Semaphore来控制任务的提交速率 ******\n\npublic class BoundedExecutor{\n    private final Executor exec;\n    private final Semaphore semaphore;\n\n    public BoundedExecutor(Executor exec, int bound) {\n        this.exec = exec;\n        this.semaphore = new Semaphore(bound);\n    }\n    \n    public void submitTask(final Runnable command) throws InterruptedException {\n        semaphore.acquire();\n        try{\n            exec.execute(new Runnable() {\n                @Override\n                public void run() {\n                    try{\n                        command.run();\n                    }finally {\n                        semaphore.release();\n                    }\n                }\n            });\n        }catch (RejectedExecutionException){\n            semaphore.release();\n        }\n    }\n}\n")])])]),n("h3",{attrs:{id:"_3-4-线程工厂"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-线程工厂"}},[e._v("#")]),e._v(" 3.4 线程工厂")]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v('****** 程序清单8-6 自定义的线程工厂 ******\n\npublic class MyThreadFactory implements ThreadFactory{\n    private final String poolName;\n\n    public MyThreadFactory(String poolName) {\n        this.poolName = poolName;\n    }\n\n    @Override\n    public Thread newThread(Runnable r) {\n        return new MyAppThread(r,poolName);\n    }\n}\n****** 程序清单8-7 定制Thread基类 ******\n\npublic class MyAppThread extends Thread{\n    public static final String DEFAULT_NAME = "MyAppThread";\n    private static volatile boolean debugLifecycle = false;\n    private static final AtomicInteger created = new AtomicInteger();\n    private static final AtomicInteger alive = new AtomicInteger();\n    private static final Logger log = Logger.getAnonymousLogger();\n    \n    public MyAppThread(Runnable r){\n        this(r,DEFAULT_NAME);\n    }\n\n    public MyAppThread(Runnable r, String name) {\n        super(r,name+"-"+created.incrementAndGet());\n        setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler(){\n            @Override\n            public void uncaughtException(Thread t, Throwable e) {\n                log.log(Level.SEVERE,"UNCAUGHT in thread"+t.getName(),e);\n            }\n        });\n    }\n\n    @Override\n    public void run() {\n        boolean debug = debugLifecycle;\n        if(debug)\n            log.log(Level.SEVERE,"created"+getName());\n        try{\n            alive.incrementAndGet();\n            super.run();\n        }finally {\n            alive.decrementAndGet();\n            if(debug)\n                log.log(Level.FINE,"exiting"+getName());\n        }\n    }\n    \n    public static int getThreadsCreated(){\n        return created.get();\n    }\n    \n    public static int getThreadsAlive(){\n        return alive.get();\n    }\n    \n    public static boolean getDebug(){\n        return debugLifecycle;\n    }\n    \n    public static void setDebug(boolean b){\n        debugLifecycle = b;\n    }\n}\n')])])]),n("h3",{attrs:{id:"_3-5-在调用构造函数后再定制threadpoolexecutor"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-5-在调用构造函数后再定制threadpoolexecutor"}},[e._v("#")]),e._v(" 3.5 在调用构造函数后再定制ThreadPoolExecutor")]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("****** 程序清单8-8 对通过标准工厂方法创建的Executor进行修改 ******\n\nExecutorService exec = Executors.newCachedThreadPool();\nif(exec instanseof ThreadPoolExecutor){\n    ((ThreadPoolExecutor)exec).setCorePoolSize(10);\n}\n")])])]),n("p",[e._v("如果将"),n("code",[e._v("ExecutorService")]),e._v("暴露给不信任的代码，又不希望对其进行修改，就可以通过"),n("code",[e._v("unconfigurableExecutorService")]),e._v("来包装它。")]),e._v(" "),n("h2",{attrs:{id:"_4-扩展threadpoolexecutor"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-扩展threadpoolexecutor"}},[e._v("#")]),e._v(" 4. 扩展ThreadPoolExecutor")]),e._v(" "),n("p",[n("code",[e._v("ThreadPoolExecutor")]),e._v("提供了扩展方法："),n("code",[e._v("brforeExecute")]),e._v(" 、"),n("code",[e._v("afterExecute")]),e._v(" 和 "),n("code",[e._v("ternimated")]),e._v("。")]),e._v(" "),n("p",[e._v("无论任务是从run中正常返回，还是抛出一个异常而返回，"),n("code",[e._v("afterExecute")]),e._v("都会被调用（如果任务在完成后带有一个error，那么就不会调用afterExecute）。如果"),n("code",[e._v("brforeExecute")]),e._v(" 抛出一个"),n("code",[e._v("RuntimeException")]),e._v("，那么任务将不被执行，并且"),n("code",[e._v("afterExecute")]),e._v("也不会被调用。")]),e._v(" "),n("p",[e._v("在线程池完成关闭操作时调用"),n("code",[e._v("terminated")]),e._v("，可以释放Executor在其生命周期里分配的各种资源。")]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v('****** 程序清单8-9 增加了日志和计时功能的线程池 ******\n\npublic class TimingThreadPool extends ThreadPoolExecutor{\n    private final ThreadLocal<Long> startTime = new ThreadLocal<>();\n    private final Logger log = Logger.getLogger("TimingThreadPool");\n    private final AtomicLong numTasks = new AtomicLong();\n    private final AtomicLong totalTime = new AtomicLong();\n\n    @Override\n    protected void beforeExecute(Thread t, Runnable r) {\n        super.beforeExecute(t,r);\n        log.fine(String.format("Thread %s: start %s",t,r));\n        startTime.set(System.nanoTime());\n    }\n\n    @Override\n    protected void afterExecute(Runnable r, Throwable t) {\n        try{\n            long endTime = System.nanoTime();\n            long taskTime = endTime - startTime.get();\n            numTasks.incrementAndGet();\n            totalTime.addAndGet(taskTime);\n            log.fine(String.format("Thread %s: end %s, time=%dns",t,r,taskTime));\n        }finally {\n            super.afterExecute(r,t);\n        }\n    }\n\n    @Override\n    protected void terminated() {\n        try{\n            log.info(String.format("Terminated: avg time=%dns",totalTime.get()/numTasks.get()));\n        }finally {\n            super.terminated();\n        }\n    }\n}\n')])])]),n("h2",{attrs:{id:"_5-递归算法的并行化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_5-递归算法的并行化"}},[e._v("#")]),e._v(" 5. 递归算法的并行化")]),e._v(" "),n("p",[e._v("当串行循环中的各个迭代操作之间彼此独立，并且每个迭代操作执行的工作量比管理一个新任务时带来的开销更多，那么这个串行循环就适合并行化。")]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("****** 程序清单8-11 将串行递归转换为并行递归 ******\n\npublic <T> void sequentialRecursive(List<Node<T>> nodes, Collection<T> results){\n    for(Node<T> n:nodes){\n        results.add(n.compute());\n        sequentialRecursive(n.getChildren(),results);\n    }\n}\n\npublic <T> void parallelRecursive(final Executor exec,List<Node<T>> nodes,final Collection<T> results){\n    for(Node<T> n:nodes){\n        exec.execute(new Runnable() {\n            @Override\n            public void run() {\n                results.add(n,compute());\n            }\n        });\n    }\n    parallelRecursive(exec,n.getChildren(),results);\n}\n")])])])])}),[],!1,null,null,null);n.default=r.exports}}]);